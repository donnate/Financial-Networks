{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import sys\n",
    "import quandl\n",
    "from utils_preprocessing import *\n",
    "from correlation import *\n",
    "from market_alphas import *\n",
    "from regression import *\n",
    "from extract_sectors import *\n",
    "from tree_attempt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path='/Users/cdonnat/Dropbox/Financial Networks/data/'\n",
    "sys.path.append(path)\n",
    "stock_data=pickle.load(open(path+'stock_data.pkl','rb'))\n",
    "Volume_data=pickle.load(open(path+'volume_data.pkl','rb'))\n",
    "new_stock_data,nb_missing_values,day_missing_values=treat_missing_data(stock_data,verbose=False)\n",
    "data_log=transform_stock(new_stock_data)\n",
    "verbose=True\n",
    "if verbose==True:\n",
    "    plt.figure()\n",
    "    plt.hist(data_log.as_matrix().reshape([-1,1]))\n",
    "    plt.title('Histogram for the log returns')\n",
    "    plt.show()\n",
    "##\n",
    "### Cap some outliers\n",
    "thres=5*(data_log.as_matrix().reshape([-1,1])).std()\n",
    "data_log=data_log.applymap(lambda x: cap(x,thres))\n",
    "if verbose==True:\n",
    "        plt.figure()\n",
    "        plt.hist(data_log.as_matrix().reshape([-1,1]))\n",
    "        plt.title('Histogram for the log returns')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "### threshold\n",
    "stock_returns=data_log.copy()\n",
    "r_m=compute_market_alpha(stock_data,stock_returns,Volume_data,plot=True)\n",
    "r_m.plot()\n",
    "from datetime import datetime\n",
    "import matplotlib.dates as mdates\n",
    "colors=['indianred','lightblue','coral','maroon','gold','orange','royalblue','mediumseagreen','violet','grey']\n",
    "bunch=np.random.choice(data_log.columns,10)\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sns.set(style='ticks')\n",
    "sns.set_context(\"paper\", font_scale=1.3)\n",
    "plt.plot_date(x=data_log.index, y=r_m,c='black',label='Market',fmt='-')\n",
    "it_b=0\n",
    "for b in bunch:\n",
    "    plt.plot_date(x=data_log.index, y=data_log[b],c=colors[it_b],label=b,fmt='-')\n",
    "    it_b+=1\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "coeff,intercept,MSE,R2=regress_stock_against_market(data_log,r_m,K=5)\n",
    "## Check stuff out\n",
    "plt.hist(R2.mean(0))\n",
    "plt.hist(MSE.mean(0))\n",
    "plt.hist(coeff.mean(0))\n",
    "plt.figure()\n",
    "plt.scatter(coeff.mean(0),R2.mean(0))\n",
    "plt.xlabel('coeff')\n",
    "plt.ylabel('R2')\n",
    "plt.title('coefficient of the regression against the market vs R2 score')\n",
    "\n",
    "betas=pd.DataFrame(coeff.mean(0)).T\n",
    "betas=pd.concat([betas]*data_log.shape[0], ignore_index=True)\n",
    "betas.index=r_m.index\n",
    "alphas=pd.DataFrame(intercept.mean(0)).T\n",
    "alphas=pd.concat([alphas]*data_log.shape[0], ignore_index=True)\n",
    "alphas.index=r_m.index\n",
    "r_m_df=pd.concat([r_m]*data_log.shape[1], axis=1)\n",
    "r_m_df.columns=betas.columns\n",
    "market_effect=betas*r_m_df+alphas\n",
    "stock_residuals=stock_returns-market_effect\n",
    "\n",
    "\n",
    "### Compute a few statistics on the residualized returns:\n",
    "plt.hist(stock_residuals.mean(0),bins=50)\n",
    "plt.hist(stock_residuals.var(0),bins=50)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sns.set(style='ticks')\n",
    "sns.set_context(\"paper\", font_scale=1.3)\n",
    "it_b=0\n",
    "for b in bunch:\n",
    "    plt.plot_date(x=data_log.index, y=stock_residuals[b],c=colors[it_b],label=b,fmt='-')\n",
    "    it_b+=1\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "cor_returns=stock_returns.corr()\n",
    "cor_res=stock_residuals.corr()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cor_returns,cmap='hot')\n",
    "plt.colorbar()\n",
    "\n",
    "ind_x,ind_y=np.tril_indices(cor_returns.shape[0])\n",
    "#mask = np.ones(cor_returns.shape,dtype='bool')\n",
    "#mask[np.tril_indices(cor_returns.shape[0])] = False\n",
    "plt.imshow(cor_res )\n",
    "#cor_ret_flattened=[cor_returns.iloc[i,j] for i,j in ind_x,ind_y]\n",
    "Betas=pd.DataFrame(betas.iloc[0,:])\n",
    "Betas.columns=['beta']\n",
    "Betas=Betas.merge(CompanyInfo.T,right_index=True,left_index=True)\n",
    "Alphas=pd.DataFrame(alphas.iloc[0,:])\n",
    "Alphas.columns=['alpha']\n",
    "CompanySector,CompanyIndustry,CompanyInfo=load_sectors(path)\n",
    "\n",
    "Betas=Betas.merge(Alphas,right_index=True,left_index=True)\n",
    "sec=pd.DataFrame(np.unique(Betas['Sector']))\n",
    "sec['key_sector']=sec.index\n",
    "ind=pd.DataFrame(np.unique(Betas['Industry']))\n",
    "ind['key_industry']=ind.index\n",
    "ind_beta=Betas.index\n",
    "Betas=Betas.merge(sec,left_on='Sector',right_on=0)\n",
    "Betas=Betas.merge(ind,left_on='Industry',right_on=0)\n",
    "del Betas['0_y']\n",
    "del Betas['0_x']\n",
    "Betas.index=ind_beta\n",
    "ind=pd.DataFrame(np.unique(Betas['Industry']))\n",
    "\n",
    "x=np.linspace(0,1,sec.shape[0])\n",
    "cmap=plt.get_cmap('plasma')\n",
    "colors_sec={}\n",
    "it=0\n",
    "for u in sec[0]:\n",
    "    colors_sec[u]=cmap(it*1.0/sec.shape[0])\n",
    "    it+=1\n",
    "Betas=Betas.merge(R2_mean,right_index=True,left_index=True)\n",
    "label_sec=[Betas.loc[u,'Sector'] for u in Betas.index]\n",
    "label_colors=[colors_sec[Betas.loc[u,'Sector']] for u in Betas.index]\n",
    "plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "for s in sec[0]:\n",
    "    ind_s=(Betas['Sector']==s)\n",
    "    try:\n",
    "        col=colors_sec[s]\n",
    "    except:\n",
    "        colors_sec[s]='black'\n",
    "        col=colors_sec[s]\n",
    "    plt.scatter(Betas.loc[ind_s,'beta'],Betas.loc[ind_s,'R2'],c=col,label=s)\n",
    "plt.xlabel('coeff')\n",
    "plt.ylabel('R2')\n",
    "plt.title('coefficient of the regression against the market vs R2 score')\n",
    "#plt.legend(loc='upper left')\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "# Put a legend to the right of the current axis\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()\n",
    "import networkx as nx\n",
    "G=nx.relabel_nodes(G,{k:list(cor_res.index)[k] for k in range(cor_res.shape[0])})\n",
    "G=nx.from_numpy_matrix(cor_res.applymap(lambda x:  x==0).as_matrix())\n",
    "\n",
    "\n",
    "thres_array=np.sort([0.5,0.4,0.2,0.175,0.15,0.125,0.1,0.075,0.05])\n",
    "degree=pd.DataFrame(np.zeros((Betas.shape[0],len(thres_array))),index=Betas.index,columns=thres_array)\n",
    "consistency=pd.DataFrame(np.zeros((Betas.shape[0],len(thres_array))),index=Betas.index,columns=thres_array)\n",
    "diversity=pd.DataFrame(np.zeros((Betas.shape[0],len(thres_array))),index=Betas.index,columns=thres_array)\n",
    "cor_res=stock_residuals.corr()\n",
    "for thres in thres_array:\n",
    "    print thres\n",
    "    cor_res=cor_res.applymap(lambda x: x*(np.abs(x)>thres))\n",
    "    print np.min(np.min(np.abs(cor_res))),np.max(np.max(np.abs(cor_res)))\n",
    "    ## Check diag\n",
    "    sector_consistency_temp=sector_consistence(Betas,cor_res)\n",
    "    consistency[thres]=sector_consistency_temp['consistency']\n",
    "    diversity[thres]=sector_consistency_temp['diversity']\n",
    "    degree[thres]=sector_consistency_temp['degree']\n",
    "    #plt.hist(sector_consistency_temp['diversity'])\n",
    "    #plt.hist(sector_consistency_temp['consistency'],bins=30)\n",
    "    #plt.hist(sector_consistency_temp['degree'],bins=30)\n",
    "    \n",
    "### Most consistent stocks per threshold\\\n",
    "l={}\n",
    "overlap=pd.DataFrame(np.zeros((Betas.shape[0],len(thres_array))),index=Betas.index,columns=thres_array)\n",
    "for thres in thres_array:\n",
    "    l[thres]=consistency[thres][consistency[thres].argsort()>Betas.shape[0]-200]\n",
    "    overlap.loc[l.index,thres]+=1\n",
    "plt.figure()\n",
    "for d in [0,1,2,4,5,10]:    \n",
    "    plt.plot(thres_array,[np.sum(degree[t]==0) for t in thres_array],label=d)\n",
    "plt.xtitle('threshold for the correlation')\n",
    "plt.ytitle('proportion of nodes with given degree')\n",
    "plt.title('Evolution of the degree with the threshold value')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path='/Users/cdonnat/Dropbox/Financial Networks/data/'\n",
    "sys.path.append(path)\n",
    "stock_data=pickle.load(open(path+'stock_data.pkl','rb'))\n",
    "new_stock_data,nb_missing_values,day_missing_values=treat_missing_data(stock_data,verbose=False)\n",
    "data_log=transform_stock(new_stock_data)\n",
    "verbose=True\n",
    "if verbose==True:\n",
    "    plt.figure()\n",
    "    plt.hist(data_log.as_matrix().reshape([-1,1]))\n",
    "    plt.title('Histogram for the log returns')\n",
    "    plt.show()\n",
    "##\n",
    "### Cap some outliers\n",
    "thres=5*(pd.concat([data_log.std()]*data_log.shape[0],1).T\n",
    "thres.index=data_log.index\n",
    "serious_outliers=((np.abs(data_log-data_log.mean())>thres))\n",
    "f,(ax1,ax2)=plt.subplots(1,2)\n",
    "ax1.hist(serious_outliers.sum(0))\n",
    "ax1.set_title('Distribution of outlier number accross stocks')\n",
    "ax2.hist(serious_outliers.sum(1))\n",
    "ax2.set_title('Distribution of outlier number accross days')\n",
    "plt.show()\n",
    "#data_log=data_log.applymap(lambda x: cap(x,thres))\n",
    "if verbose==True:\n",
    "    plt.figure()\n",
    "    plt.hist(data_log.as_matrix().reshape([-1,1]))\n",
    "    plt.title('Histogram for the log returns')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree=agg_clustering(cor_res,weights,stepsize=0.01)\n",
    "edges,odes=edges_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "if len(x)==0:\n",
    "    x=np.linspace(0,1,100)\n",
    "plt.scatter( [xx for xx in tree.keys()], [np.mean([len(g) for g in tree[xx].values()]) for xx in tree.keys()],label='avg size grouping',c='blue')\n",
    "plt.scatter( [xx for xx in tree.keys()],[len(tree[xx]) for xx in tree.keys()],c='black',label='nb groups added')\n",
    "plt.xlabel('Correlation Threshold')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "G=nx.from_pandas_dataframe(edges,source='Source',target='Target')\n",
    "print 'nb connected components:',nx.number_connected_components(G)\n",
    "for u in nx.connected_component_subgraphs(G):\n",
    "    print 'size cmpt: \\t'+str(u.number_of_edges())+'\\n'\n",
    "i=0\n",
    "for u in nx.connected_component_subgraphs(G):\n",
    "    i+=1\n",
    "    if i>1:\n",
    "        print 'cmpt'+str(i)+': \\t'+u.nodes()+'\\n'\n",
    "industry_diversity={}\n",
    "for xx in tree.keys():\n",
    "    industry_diversity[xx]={}\n",
    "    for grp_key in tree[xx].keys():\n",
    "        grp=tree[xx][grp_key]\n",
    "        industry_diversity[xx][grp_key]=[np.sum(nodes.loc[tree[xx][grp_key],'keys_s']==ind) for ind in np.unique(nodes['keys_s'])]\n",
    "div=[]    \n",
    "for xx in industry_diversity.keys():\n",
    "    for jj in industry_diversity[xx].keys():\n",
    "        div.append(industry_diversity[xx][jj]+[xx])\n",
    "nodes['keys_s2']=nodes['keys_s'].copy()\n",
    "nodes_bis=[]\n",
    "for xx in np.sort(list(tree.keys()))[::-1]:\n",
    "    for grp_key in tree[xx].keys():\n",
    "        nd='lev_'+str(1-xx)[:4]+'_'+str(grp_key)\n",
    "        ind=pd.DataFrame([np.sum(nodes.loc[tree[xx][grp_key],'keys_s']==ind) for ind in np.unique(nodes['keys_s'])],index=np.unique(nodes['keys_s']),columns=['c'])            \n",
    "        ind=ind.sort_values(by='c',ascending=False)\n",
    "        if (ind.iloc[1]==0).bool() &(ind.index[0]==20 ):\n",
    "            nodes.loc[nd,'keys_s2']=20\n",
    "        elif (ind.iloc[1]>0).bool() &(ind.index[0]==20 ):\n",
    "            if (ind.iloc[2]==ind.iloc[1]).bool():\n",
    "                nodes_bis.append((nd,ind))\n",
    "            nodes.loc[nd,'keys_s2']=float(ind.index[1])\n",
    "        else:\n",
    "            if (ind.iloc[0]==ind.iloc[1]).bool():\n",
    "                nodes_bis.append((nd,ind))\n",
    "            nodes.loc[nd,'keys_s2']=float(ind.index[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "div=pd.DataFrame(np.array(div),columns= [nodes.loc[nodes['keys_s']==j,'Sector'][0] for j in np.unique(nodes['keys_s'])]+['corr'])\n",
    "nb_activated=div.apply(lambda x: np.sum([xx!=0 for xx in x[:-2]])/np.sum([xx!=0 for xx in x[:-2]]),axis=1)\n",
    "nb_activated2=div.iloc[:,:-1]    \n",
    " nb_activated2=nb_activated2.apply(lambda x: x/np.sum(x), axis=1)\n",
    " plt.hist(nb_activated2.iloc[:,12])\n",
    " for u in nb_activated2.columns:\n",
    "     plt.figure()\n",
    "     plt.hist(nb_activated2[u])\n",
    "     plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
